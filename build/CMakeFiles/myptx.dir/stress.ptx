//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-29069683
// Cuda compilation tools, release 11.1, V11.1.74
// Based on LLVM 3.4svn
//

.version 7.1
.target sm_61
.address_size 64

	// .globl	_Z8launchSMPii
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
// _ZZ8launchSMPiiE7blk_log has been demoted
.shared .align 8 .u64 clock_begin;
.shared .align 8 .u64 clock_now;
.global .align 1 .b8 $str[32] = {49, 54, 45, 119, 97, 114, 112, 32, 115, 117, 115, 112, 101, 110, 115, 105, 111, 110, 32, 98, 108, 111, 99, 107, 32, 111, 110, 32, 37, 100, 10, 0};
.global .align 1 .b8 $str$1[27] = {98, 108, 111, 99, 107, 32, 114, 101, 116, 117, 114, 110, 101, 100, 32, 111, 110, 32, 115, 109, 105, 100, 32, 37, 100, 10, 0};
.global .align 1 .b8 $str$2[14] = {66, 65, 68, 32, 84, 72, 68, 32, 73, 68, 32, 37, 100, 0};
.global .align 1 .b8 $str$3[15] = {66, 65, 68, 32, 87, 82, 80, 32, 73, 68, 32, 37, 100, 10, 0};
.global .align 1 .b8 $str$4[92] = {37, 100, 32, 98, 108, 111, 99, 107, 115, 32, 120, 32, 37, 100, 32, 119, 97, 114, 112, 115, 47, 98, 108, 111, 99, 107, 32, 111, 102, 32, 109, 101, 109, 111, 114, 121, 46, 32, 37, 100, 32, 119, 97, 114, 112, 115, 47, 98, 108, 111, 99, 107, 32, 97, 114, 101, 32, 114, 101, 97, 100, 115, 44, 32, 116, 111, 116, 97, 108, 108, 105, 110, 103, 32, 37, 100, 32, 119, 97, 114, 112, 115, 32, 112, 101, 114, 32, 83, 77, 46, 10, 0};
.global .align 1 .b8 $str$5[17] = {66, 65, 68, 32, 83, 84, 82, 73, 68, 69, 32, 83, 73, 90, 69, 10, 0};
.global .align 1 .b8 $str$6[42] = {101, 108, 101, 109, 101, 110, 116, 115, 32, 100, 111, 110, 39, 116, 32, 100, 105, 118, 105, 100, 101, 32, 105, 110, 116, 111, 32, 98, 108, 111, 99, 107, 115, 32, 101, 118, 101, 110, 108, 121, 10, 0};
.global .align 1 .b8 $str$7[43] = {101, 108, 101, 109, 101, 110, 116, 115, 32, 100, 111, 110, 39, 116, 32, 100, 105, 118, 105, 100, 101, 32, 105, 110, 116, 111, 32, 116, 104, 114, 101, 97, 100, 115, 32, 101, 118, 101, 110, 108, 121, 10, 0};
.global .align 1 .b8 $str$8[33] = {110, 111, 116, 32, 101, 110, 111, 117, 103, 104, 32, 101, 108, 101, 109, 101, 110, 116, 115, 32, 102, 111, 114, 32, 116, 104, 114, 101, 97, 100, 115, 10, 0};
.global .align 1 .b8 $str$9[62] = {37, 100, 32, 98, 108, 111, 99, 107, 115, 32, 120, 32, 37, 100, 32, 119, 97, 114, 112, 115, 47, 98, 108, 111, 99, 107, 32, 111, 102, 32, 109, 101, 109, 111, 114, 121, 46, 32, 37, 100, 32, 119, 97, 114, 112, 115, 47, 98, 108, 111, 99, 107, 32, 97, 114, 101, 32, 102, 112, 46, 10, 0};
.global .align 1 .b8 $str$10[30] = {66, 65, 68, 32, 67, 79, 77, 80, 85, 84, 69, 32, 73, 78, 83, 84, 82, 32, 84, 89, 80, 69, 32, 86, 65, 76, 85, 69, 10, 0};

.visible .entry _Z8launchSMPii(
	.param .u64 _Z8launchSMPii_param_0,
	.param .u32 _Z8launchSMPii_param_1
)
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<56>;
	.reg .b64 	%rd<60>;
	// demoted variable
	.shared .align 2 .b8 _ZZ8launchSMPiiE7blk_log[32768];

	ld.param.u64 	%rd5, [_Z8launchSMPii_param_0];
	ld.param.u32 	%r15, [_Z8launchSMPii_param_1];
	cvta.to.global.u64 	%rd1, %rd5;
	// inline asm
	mov.u32 %r16, %smid;
	// inline asm
	setp.ne.s32	%p1, %r16, 0;
	@%p1 bra 	BB0_6;

	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.x;
	mov.u32 	%r20, %tid.x;
	mad.lo.s32 	%r21, %r19, %r18, %r20;
	shr.s32 	%r22, %r21, 31;
	shr.u32 	%r23, %r22, 27;
	add.s32 	%r24, %r21, %r23;
	shr.s32 	%r1, %r24, 5;
	mov.u32 	%r2, %ctaid.x;
	mul.wide.u32 	%rd6, %r2, -858993459;
	shr.u64 	%rd7, %rd6, 36;
	cvt.u32.u64	%r25, %rd7;
	mul.lo.s32 	%r3, %r15, 32640;
	shl.b32 	%r26, %r1, 8;
	mad.lo.s32 	%r27, %r25, 8192, %r26;
	shl.b32 	%r28, %r27, 1;
	mov.u32 	%r29, _ZZ8launchSMPiiE7blk_log;
	add.s32 	%r52, %r29, %r28;
	mov.u32 	%r53, -256;

BB0_2:
	// inline asm
	mov.u64 	%rd8, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd9, %clock64;
	// inline asm
	sub.s64 	%rd40, %rd9, %rd8;
	st.shared.u16 	[%r52], %rd40;
	// inline asm
	mov.u64 	%rd10, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd11, %clock64;
	// inline asm
	sub.s64 	%rd41, %rd11, %rd10;
	st.shared.u16 	[%r52+2], %rd41;
	// inline asm
	mov.u64 	%rd12, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd13, %clock64;
	// inline asm
	sub.s64 	%rd42, %rd13, %rd12;
	st.shared.u16 	[%r52+4], %rd42;
	// inline asm
	mov.u64 	%rd14, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd15, %clock64;
	// inline asm
	sub.s64 	%rd43, %rd15, %rd14;
	st.shared.u16 	[%r52+6], %rd43;
	// inline asm
	mov.u64 	%rd16, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd17, %clock64;
	// inline asm
	sub.s64 	%rd44, %rd17, %rd16;
	st.shared.u16 	[%r52+8], %rd44;
	// inline asm
	mov.u64 	%rd18, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd19, %clock64;
	// inline asm
	sub.s64 	%rd45, %rd19, %rd18;
	st.shared.u16 	[%r52+10], %rd45;
	// inline asm
	mov.u64 	%rd20, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd21, %clock64;
	// inline asm
	sub.s64 	%rd46, %rd21, %rd20;
	st.shared.u16 	[%r52+12], %rd46;
	// inline asm
	mov.u64 	%rd22, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd23, %clock64;
	// inline asm
	sub.s64 	%rd47, %rd23, %rd22;
	st.shared.u16 	[%r52+14], %rd47;
	// inline asm
	mov.u64 	%rd24, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd25, %clock64;
	// inline asm
	sub.s64 	%rd48, %rd25, %rd24;
	st.shared.u16 	[%r52+16], %rd48;
	// inline asm
	mov.u64 	%rd26, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd27, %clock64;
	// inline asm
	sub.s64 	%rd49, %rd27, %rd26;
	st.shared.u16 	[%r52+18], %rd49;
	// inline asm
	mov.u64 	%rd28, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd29, %clock64;
	// inline asm
	sub.s64 	%rd50, %rd29, %rd28;
	st.shared.u16 	[%r52+20], %rd50;
	// inline asm
	mov.u64 	%rd30, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd31, %clock64;
	// inline asm
	sub.s64 	%rd51, %rd31, %rd30;
	st.shared.u16 	[%r52+22], %rd51;
	// inline asm
	mov.u64 	%rd32, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd33, %clock64;
	// inline asm
	sub.s64 	%rd52, %rd33, %rd32;
	st.shared.u16 	[%r52+24], %rd52;
	// inline asm
	mov.u64 	%rd34, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd35, %clock64;
	// inline asm
	sub.s64 	%rd53, %rd35, %rd34;
	st.shared.u16 	[%r52+26], %rd53;
	// inline asm
	mov.u64 	%rd36, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd37, %clock64;
	// inline asm
	sub.s64 	%rd54, %rd37, %rd36;
	st.shared.u16 	[%r52+28], %rd54;
	// inline asm
	mov.u64 	%rd38, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd39, %clock64;
	// inline asm
	sub.s64 	%rd55, %rd39, %rd38;
	st.shared.u16 	[%r52+30], %rd55;
	add.s32 	%r52, %r52, 32;
	add.s32 	%r53, %r53, 16;
	setp.ne.s32	%p2, %r53, 0;
	@%p2 bra 	BB0_2;

	mul.lo.s32 	%r9, %r15, 255;
	bar.sync 	0;
	add.s32 	%r54, %r29, %r28;
	mul.wide.s32 	%rd2, %r27, 4;
	mov.u32 	%r55, -256;
	mov.u64 	%rd59, %rd1;

BB0_4:
	ld.shared.u16 	%r36, [%r54];
	add.s64 	%rd58, %rd59, %rd2;
	st.global.u32 	[%rd58], %r36;
	ld.shared.u16 	%r37, [%r54+2];
	st.global.u32 	[%rd58+4], %r37;
	ld.shared.u16 	%r38, [%r54+4];
	st.global.u32 	[%rd58+8], %r38;
	ld.shared.u16 	%r39, [%r54+6];
	st.global.u32 	[%rd58+12], %r39;
	ld.shared.u16 	%r40, [%r54+8];
	st.global.u32 	[%rd58+16], %r40;
	ld.shared.u16 	%r41, [%r54+10];
	st.global.u32 	[%rd58+20], %r41;
	ld.shared.u16 	%r42, [%r54+12];
	st.global.u32 	[%rd58+24], %r42;
	ld.shared.u16 	%r43, [%r54+14];
	st.global.u32 	[%rd58+28], %r43;
	ld.shared.u16 	%r44, [%r54+16];
	st.global.u32 	[%rd58+32], %r44;
	ld.shared.u16 	%r45, [%r54+18];
	st.global.u32 	[%rd58+36], %r45;
	ld.shared.u16 	%r46, [%r54+20];
	st.global.u32 	[%rd58+40], %r46;
	ld.shared.u16 	%r47, [%r54+22];
	st.global.u32 	[%rd58+44], %r47;
	ld.shared.u16 	%r48, [%r54+24];
	st.global.u32 	[%rd58+48], %r48;
	ld.shared.u16 	%r49, [%r54+26];
	st.global.u32 	[%rd58+52], %r49;
	ld.shared.u16 	%r50, [%r54+28];
	st.global.u32 	[%rd58+56], %r50;
	ld.shared.u16 	%r51, [%r54+30];
	st.global.u32 	[%rd58+60], %r51;
	add.s64 	%rd59, %rd59, 64;
	add.s32 	%r54, %r54, 32;
	add.s32 	%r55, %r55, 16;
	setp.ne.s32	%p3, %r55, 0;
	@%p3 bra 	BB0_4;

	st.global.u32 	[%rd1], %r3;
	st.global.u32 	[%rd1+4], %r9;

BB0_6:
	ret;
}

	// .globl	_Z10testKernelPy
.visible .entry _Z10testKernelPy(
	.param .u64 _Z10testKernelPy_param_0
)
{
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<7>;


	ld.param.u64 	%rd2, [_Z10testKernelPy_param_0];
	cvta.to.global.u64 	%rd3, %rd2;
	// inline asm
	mov.u64 	%rd1, %clock64;
	// inline asm
	mov.u32 	%r2, %ctaid.x;
	mul.wide.u32 	%rd4, %r2, 8;
	add.s64 	%rd5, %rd3, %rd4;
	st.global.u64 	[%rd5], %rd1;
	// inline asm
	mov.u32 %r1, %smid;
	// inline asm
	cvt.s64.s32	%rd6, %r1;
	st.global.u64 	[%rd5+160], %rd6;
	ret;
}

	// .globl	_Z8occupySMPiy
.visible .entry _Z8occupySMPiy(
	.param .u64 _Z8occupySMPiy_param_0,
	.param .u64 _Z8occupySMPiy_param_1
)
{
	.local .align 8 .b8 	__local_depot2[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<5>;
	.reg .b32 	%r<12>;
	.reg .b64 	%rd<16>;


	mov.u64 	%SPL, __local_depot2;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd2, [_Z8occupySMPiy_param_0];
	ld.param.u64 	%rd3, [_Z8occupySMPiy_param_1];
	// inline asm
	mov.u32 %r4, %smid;
	// inline asm
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r6, %tid.y;
	mul.lo.s32 	%r2, %r5, %r6;
	mov.u32 	%r3, %tid.x;
	neg.s32 	%r7, %r3;
	setp.ne.s32	%p1, %r2, %r7;
	@%p1 bra 	BB2_2;

	add.u64 	%rd4, %SP, 0;
	add.u64 	%rd5, %SPL, 0;
	st.local.u32 	[%rd5], %r4;
	mov.u64 	%rd6, $str;
	cvta.global.u64 	%rd7, %rd6;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd4;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r8, [retval0+0];
	
	//{
	}// Callseq End 0

BB2_2:
	add.s32 	%r9, %r3, %r2;
	add.s32 	%r10, %r9, 31;
	setp.lt.u32	%p2, %r10, 63;
	@%p2 bra 	BB2_4;
	bra.uni 	BB2_3;

BB2_4:
	// inline asm
	mov.u64 %rd8, %globaltimer;
	// inline asm
	st.shared.u64 	[clock_begin], %rd8;
	st.shared.u64 	[clock_now], %rd8;
	add.s64 	%rd1, %rd3, 100;
	setp.eq.s64	%p3, %rd1, 0;
	@%p3 bra 	BB2_6;

BB2_5:
	// inline asm
	mov.u64 %rd9, %globaltimer;
	// inline asm
	st.shared.u64 	[clock_now], %rd9;
	ld.shared.u64 	%rd10, [clock_begin];
	sub.s64 	%rd11, %rd9, %rd10;
	setp.lt.u64	%p4, %rd11, %rd1;
	@%p4 bra 	BB2_5;

BB2_6:
	bar.sync 	0;
	bra.uni 	BB2_7;

BB2_3:
	bar.sync 	0;

BB2_7:
	// inline asm
	mov.u64 %rd12, %globaltimer;
	// inline asm
	st.shared.u64 	[clock_now], %rd12;
	mov.u32 	%r11, %ctaid.x;
	cvta.to.global.u64 	%rd13, %rd2;
	mul.wide.u32 	%rd14, %r11, 4;
	add.s64 	%rd15, %rd13, %rd14;
	st.global.u32 	[%rd15], %rd12;
	ret;
}

	// .globl	_Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii
.visible .entry _Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii(
	.param .u64 _Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_0,
	.param .u64 _Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_1,
	.param .u32 _Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_2,
	.param .u64 _Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_3,
	.param .u32 _Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_4,
	.param .u64 _Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_5,
	.param .u8 _Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_6,
	.param .u8 _Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_7,
	.param .u32 _Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_8,
	.param .u32 _Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_9,
	.param .u32 _Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_10,
	.param .u8 _Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_11,
	.param .u32 _Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_12,
	.param .u32 _Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_13
)
{
	.local .align 16 .b8 	__local_depot3[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<47>;
	.reg .b16 	%rs<9>;
	.reg .b32 	%r<138>;
	.reg .b64 	%rd<50>;


	mov.u64 	%SPL, __local_depot3;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd4, [_Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_0];
	ld.param.u64 	%rd2, [_Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_1];
	ld.param.u32 	%r61, [_Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_2];
	ld.param.u64 	%rd3, [_Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_3];
	ld.param.u32 	%r62, [_Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_4];
	ld.param.u32 	%r63, [_Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_8];
	ld.param.u32 	%r64, [_Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_9];
	ld.param.u32 	%r65, [_Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_10];
	ld.param.u32 	%r66, [_Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_12];
	ld.param.u32 	%r67, [_Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_13];
	ld.param.s8 	%rs3, [_Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_11];
	ld.param.s8 	%rs2, [_Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_7];
	ld.param.s8 	%rs1, [_Z20memoryKernelSingleSMPPjPiiyiS_bbiiibii_param_6];
	cvta.to.global.u64 	%rd5, %rd4;
	ld.global.u64 	%rd1, [%rd5];
	// inline asm
	mov.u32 %r68, %smid;
	// inline asm
	setp.gt.s32	%p2, %r63, %r64;
	and.b16  	%rs4, %rs3, 255;
	setp.eq.s16	%p3, %rs4, 0;
	and.pred  	%p4, %p3, %p2;
	setp.ge.s32	%p5, %r68, %r64;
	and.pred  	%p6, %p4, %p5;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.y;
	mul.lo.s32 	%r4, %r2, %r3;
	mov.u32 	%r5, %tid.x;
	@%p6 bra 	BB3_36;
	bra.uni 	BB3_1;

BB3_36:
	neg.s32 	%r114, %r5;
	setp.ne.s32	%p46, %r4, %r114;
	@%p46 bra 	BB3_38;

	add.u64 	%rd46, %SP, 0;
	add.u64 	%rd47, %SPL, 0;
	st.local.u32 	[%rd47], %r68;
	mov.u64 	%rd48, $str$1;
	cvta.global.u64 	%rd49, %rd48;
	// Callseq Start 8
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd49;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd46;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r115, [retval0+0];
	
	//{
	}// Callseq End 8
	bra.uni 	BB3_38;

BB3_1:
	mov.u32 	%r6, %ntid.y;
	mul.lo.s32 	%r7, %r6, %r2;
	add.s32 	%r116, %r4, %r5;
	setp.lt.u32	%p7, %r116, %r7;
	@%p7 bra 	BB3_3;

	add.u64 	%rd6, %SP, 0;
	add.u64 	%rd7, %SPL, 0;
	st.local.u32 	[%rd7], %r116;
	mov.u64 	%rd8, $str$2;
	cvta.global.u64 	%rd9, %rd8;
	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd6;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r69, [retval0+0];
	
	//{
	}// Callseq End 1

BB3_3:
	mul.lo.s32 	%r117, %r7, %r63;
	and.b16  	%rs5, %rs1, 255;
	setp.ne.s16	%p8, %rs5, 0;
	@%p8 bra 	BB3_6;

	shr.s32 	%r70, %r117, 31;
	shr.u32 	%r71, %r70, 27;
	add.s32 	%r72, %r117, %r71;
	shr.s32 	%r117, %r72, 5;
	shr.s32 	%r73, %r116, 31;
	shr.u32 	%r74, %r73, 27;
	add.s32 	%r75, %r116, %r74;
	shr.s32 	%r116, %r75, 5;
	setp.le.u32	%p9, %r116, %r6;
	@%p9 bra 	BB3_6;

	add.u64 	%rd10, %SP, 0;
	add.u64 	%rd11, %SPL, 0;
	st.local.u32 	[%rd11], %r116;
	mov.u64 	%rd12, $str$3;
	cvta.global.u64 	%rd13, %rd12;
	// Callseq Start 2
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd13;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd10;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r76, [retval0+0];
	
	//{
	}// Callseq End 2

BB3_6:
	mov.u32 	%r77, %ctaid.x;
	setp.gt.s32	%p10, %r77, 19;
	and.pred  	%p12, %p10, %p3;
	add.s32 	%r78, %r64, -20;
	selp.b32	%r79, %r78, 0, %p12;
	add.s32 	%r80, %r79, %r77;
	setp.ne.s32	%p13, %r80, 0;
	setp.lt.s32	%p14, %r67, 0;
	or.pred  	%p15, %p14, %p13;
	setp.ne.s32	%p16, %r5, 0;
	or.pred  	%p17, %p15, %p16;
	setp.ne.s32	%p18, %r3, 0;
	or.pred  	%p19, %p17, %p18;
	@%p19 bra 	BB3_8;

	mul.lo.s32 	%r81, %r67, %r63;
	div.s32 	%r82, %r81, %r64;
	add.u64 	%rd14, %SP, 0;
	add.u64 	%rd15, %SPL, 0;
	st.local.u32 	[%rd15], %r63;
	st.local.u32 	[%rd15+4], %r6;
	st.local.u32 	[%rd15+8], %r67;
	st.local.u32 	[%rd15+12], %r82;
	mov.u64 	%rd16, $str$4;
	cvta.global.u64 	%rd17, %rd16;
	// Callseq Start 3
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd17;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd14;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r83, [retval0+0];
	
	//{
	}// Callseq End 3

BB3_8:
	setp.gt.s32	%p20, %r67, -1;
	setp.ge.u32	%p21, %r3, %r67;
	selp.u32	%r84, 1, 0, %p21;
	selp.b32	%r14, %r84, %r66, %p20;
	shr.s32 	%r85, %r65, 31;
	shr.u32 	%r86, %r85, 30;
	add.s32 	%r87, %r65, %r86;
	shr.s32 	%r15, %r87, 2;
	shr.s32 	%r88, %r61, 31;
	shr.u32 	%r89, %r88, 30;
	add.s32 	%r90, %r61, %r89;
	shr.s32 	%r16, %r90, 2;
	div.s32 	%r17, %r16, %r117;
	div.s32 	%r91, %r61, %r65;
	div.s32 	%r18, %r91, %r117;
	setp.gt.s32	%p22, %r65, 3;
	@%p22 bra 	BB3_10;

	mov.u64 	%rd18, $str$5;
	cvta.global.u64 	%rd19, %rd18;
	mov.u64 	%rd20, 0;
	// Callseq Start 4
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd19;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd20;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r92, [retval0+0];
	
	//{
	}// Callseq End 4

BB3_10:
	rem.s32 	%r93, %r16, %r63;
	setp.eq.s32	%p23, %r93, 0;
	@%p23 bra 	BB3_12;

	mov.u64 	%rd21, $str$6;
	cvta.global.u64 	%rd22, %rd21;
	mov.u64 	%rd23, 0;
	// Callseq Start 5
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd22;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd23;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r94, [retval0+0];
	
	//{
	}// Callseq End 5

BB3_12:
	rem.s32 	%r95, %r16, %r117;
	setp.eq.s32	%p24, %r95, 0;
	@%p24 bra 	BB3_14;

	mov.u64 	%rd24, $str$7;
	cvta.global.u64 	%rd25, %rd24;
	mov.u64 	%rd26, 0;
	// Callseq Start 6
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd25;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd26;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r96, [retval0+0];
	
	//{
	}// Callseq End 6

BB3_14:
	setp.ge.s32	%p25, %r16, %r117;
	@%p25 bra 	BB3_16;

	mov.u64 	%rd27, $str$8;
	cvta.global.u64 	%rd28, %rd27;
	mov.u64 	%rd29, 0;
	// Callseq Start 7
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd28;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd29;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r97, [retval0+0];
	
	//{
	}// Callseq End 7

BB3_16:
	div.s32 	%r98, %r16, %r63;
	mul.lo.s32 	%r103, %r17, %r116;
	mad.lo.s32 	%r134, %r98, %r80, %r103;
	bar.sync 	0;
	// inline asm
	mov.u64 %rd30, %globaltimer;
	// inline asm
	st.shared.u64 	[clock_begin], %rd30;
	st.shared.u64 	[clock_now], %rd30;
	setp.eq.s64	%p29, %rd3, -100;
	mov.u32 	%r135, 0;
	@%p29 bra 	BB3_35;

	shl.b32 	%r106, %r62, 11;
	add.s32 	%r20, %r106, 2048;
	setp.lt.s32	%p30, %r18, 1;
	setp.ne.s32	%p31, %r14, 3;
	or.pred  	%p1, %p31, %p30;
	mov.u32 	%r135, 0;
	and.b16  	%rs8, %rs2, 255;

BB3_18:
	setp.eq.s16	%p32, %rs8, 0;
	@%p32 bra 	BB3_22;
	bra.uni 	BB3_19;

BB3_22:
	setp.eq.s32	%p35, %r14, 0;
	@%p35 bra 	BB3_32;
	bra.uni 	BB3_23;

BB3_32:
	neg.s32 	%r131, %r18;
	mov.u32 	%r132, %r134;
	@%p30 bra 	BB3_34;

BB3_33:
	mul.wide.s32 	%rd39, %r132, 4;
	add.s64 	%rd40, %rd1, %rd39;
	ld.u32 	%r113, [%rd40];
	add.s32 	%r135, %r113, %r135;
	add.s32 	%r132, %r132, %r15;
	add.s32 	%r131, %r131, 1;
	setp.ne.s32	%p44, %r131, 0;
	@%p44 bra 	BB3_33;
	bra.uni 	BB3_34;

BB3_19:
	mov.u32 	%r120, 0;
	setp.lt.s32	%p33, %r20, 1;
	@%p33 bra 	BB3_34;

BB3_20:
	add.s32 	%r135, %r120, %r135;
	add.s32 	%r120, %r120, 1;
	setp.lt.s32	%p34, %r120, %r20;
	@%p34 bra 	BB3_20;

	add.s32 	%r134, %r120, -1;
	bra.uni 	BB3_34;

BB3_23:
	setp.eq.s32	%p36, %r14, 1;
	@%p36 bra 	BB3_30;
	bra.uni 	BB3_24;

BB3_30:
	neg.s32 	%r129, %r18;
	mov.u32 	%r130, %r134;
	@%p30 bra 	BB3_34;

BB3_31:
	mul.wide.s32 	%rd37, %r130, 4;
	add.s64 	%rd38, %rd1, %rd37;
	mov.u32 	%r112, 7;
	st.u32 	[%rd38], %r112;
	add.s32 	%r130, %r130, %r15;
	add.s32 	%r129, %r129, 1;
	setp.eq.s32	%p42, %r129, 0;
	@%p42 bra 	BB3_34;
	bra.uni 	BB3_31;

BB3_24:
	setp.eq.s32	%p37, %r14, 2;
	@%p37 bra 	BB3_28;
	bra.uni 	BB3_25;

BB3_28:
	neg.s32 	%r126, %r18;
	mov.u32 	%r127, %r134;
	@%p30 bra 	BB3_34;

BB3_29:
	mul.wide.s32 	%rd35, %r127, 4;
	add.s64 	%rd36, %rd1, %rd35;
	ld.u32 	%r110, [%rd36];
	add.s32 	%r135, %r110, %r135;
	mov.u32 	%r111, 7;
	st.u32 	[%rd36], %r111;
	add.s32 	%r127, %r127, %r15;
	add.s32 	%r126, %r126, 1;
	setp.eq.s32	%p40, %r126, 0;
	@%p40 bra 	BB3_34;
	bra.uni 	BB3_29;

BB3_25:
	@%p1 bra 	BB3_34;

	add.s32 	%r124, %r62, %r134;
	neg.s32 	%r122, %r18;
	mov.u32 	%r123, %r134;

BB3_27:
	mul.wide.s32 	%rd31, %r123, 4;
	add.s64 	%rd32, %rd1, %rd31;
	mov.u32 	%r108, 7;
	st.u32 	[%rd32], %r108;
	mul.wide.s32 	%rd33, %r124, 4;
	add.s64 	%rd34, %rd1, %rd33;
	ld.u32 	%r109, [%rd34];
	add.s32 	%r135, %r109, %r135;
	add.s32 	%r124, %r124, %r15;
	add.s32 	%r123, %r123, %r15;
	add.s32 	%r122, %r122, 1;
	setp.eq.s32	%p38, %r122, 0;
	@%p38 bra 	BB3_34;
	bra.uni 	BB3_27;

BB3_34:
	// inline asm
	mov.u64 %rd41, %globaltimer;
	// inline asm
	st.shared.u64 	[clock_now], %rd41;
	ld.shared.u64 	%rd42, [clock_begin];
	sub.s64 	%rd43, %rd41, %rd42;
	add.s64 	%rd44, %rd3, 100;
	setp.lt.u64	%p45, %rd43, %rd44;
	@%p45 bra 	BB3_18;

BB3_35:
	bar.sync 	0;
	cvta.to.global.u64 	%rd45, %rd2;
	st.global.u32 	[%rd45+4], %r18;
	st.global.u32 	[%rd45+8], %r134;
	st.global.u32 	[%rd45+12], %r135;

BB3_38:
	ret;
}

	// .globl	_Z13computeKernelPPjPiiyiiiii
.visible .entry _Z13computeKernelPPjPiiyiiiii(
	.param .u64 _Z13computeKernelPPjPiiyiiiii_param_0,
	.param .u64 _Z13computeKernelPPjPiiyiiiii_param_1,
	.param .u32 _Z13computeKernelPPjPiiyiiiii_param_2,
	.param .u64 _Z13computeKernelPPjPiiyiiiii_param_3,
	.param .u32 _Z13computeKernelPPjPiiyiiiii_param_4,
	.param .u32 _Z13computeKernelPPjPiiyiiiii_param_5,
	.param .u32 _Z13computeKernelPPjPiiyiiiii_param_6,
	.param .u32 _Z13computeKernelPPjPiiyiiiii_param_7,
	.param .u32 _Z13computeKernelPPjPiiyiiiii_param_8
)
{
	.local .align 8 .b8 	__local_depot4[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<115>;
	.reg .b16 	%rs<461>;
	.reg .f32 	%f<144>;
	.reg .b32 	%r<358>;
	.reg .f64 	%fd<97>;
	.reg .b64 	%rd<168>;


	mov.u64 	%SPL, __local_depot4;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd16, [_Z13computeKernelPPjPiiyiiiii_param_3];
	ld.param.u32 	%r103, [_Z13computeKernelPPjPiiyiiiii_param_5];
	ld.param.u32 	%r104, [_Z13computeKernelPPjPiiyiiiii_param_6];
	ld.param.u32 	%r105, [_Z13computeKernelPPjPiiyiiiii_param_7];
	ld.param.u32 	%r106, [_Z13computeKernelPPjPiiyiiiii_param_8];
	mov.u32 	%r108, %ctaid.x;
	setp.eq.s32	%p1, %r108, 0;
	setp.gt.s32	%p2, %r106, -1;
	and.pred  	%p3, %p2, %p1;
	mov.u32 	%r109, %tid.x;
	setp.eq.s32	%p4, %r109, 0;
	and.pred  	%p5, %p3, %p4;
	mov.u32 	%r1, %tid.y;
	setp.eq.s32	%p6, %r1, 0;
	and.pred  	%p7, %p5, %p6;
	@!%p7 bra 	BB4_2;
	bra.uni 	BB4_1;

BB4_1:
	mov.u32 	%r110, %nctaid.x;
	add.u64 	%rd17, %SP, 0;
	add.u64 	%rd18, %SPL, 0;
	st.local.u32 	[%rd18], %r110;
	mov.u32 	%r111, %ntid.y;
	st.local.u32 	[%rd18+4], %r111;
	st.local.u32 	[%rd18+8], %r106;
	mov.u64 	%rd19, $str$9;
	cvta.global.u64 	%rd20, %rd19;
	// Callseq Start 9
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd20;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd17;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r112, [retval0+0];
	
	//{
	}// Callseq End 9

BB4_2:
	bar.sync 	0;
	// inline asm
	mov.u64 %rd21, %globaltimer;
	// inline asm
	st.shared.u64 	[clock_begin], %rd21;
	st.shared.u64 	[clock_now], %rd21;
	mov.f32 	%f142, 0f00000000;
	// inline asm
	{  cvt.rn.f16.f32 %rs457, %f142;}

	// inline asm
	mov.f32 	%f21, 0f3F8CCCCD;
	// inline asm
	{  cvt.rn.f16.f32 %rs34, %f21;}

	// inline asm
	mov.f32 	%f22, 0f3FA66666;
	// inline asm
	{  cvt.rn.f16.f32 %rs35, %f22;}

	// inline asm
	cvt.u16.u32	%rs4, %r104;
	cvt.s64.s32	%rd1, %r104;
	add.s64 	%rd2, %rd16, 100;
	setp.eq.s64	%p8, %rd2, 0;
	mov.f64 	%fd95, 0d0000000000000000;
	mov.u16 	%rs451, 0;
	mov.u32 	%r354, 0;
	mov.u64 	%rd164, 0;
	@%p8 bra 	BB4_3;

	shr.s32 	%r118, %r105, 31;
	shr.u32 	%r119, %r118, 27;
	add.s32 	%r120, %r105, %r119;
	and.b32  	%r2, %r120, -32;
	setp.lt.u32	%p9, %r1, %r106;
	selp.b32	%r121, 2, 8, %p9;
	selp.b32	%r15, %r121, %r103, %p2;
	mov.f32 	%f142, 0f00000000;
	mov.f64 	%fd95, 0d0000000000000000;
	mov.u16 	%rs451, 0;
	mov.u32 	%r354, 0;
	mov.u64 	%rd164, 0;
	mov.u32 	%r332, %r354;
	bra.uni 	BB4_5;

BB4_3:
	mov.u32 	%r332, %r354;
	bra.uni 	BB4_114;

BB4_81:
	mov.u32 	%r332, %r104;
	bra.uni 	BB4_113;

BB4_75:
	mov.u64 	%rd164, %rd1;
	bra.uni 	BB4_113;

BB4_87:
	mov.u16 	%rs451, %rs4;
	bra.uni 	BB4_113;

BB4_65:
	mov.u32 	%r352, %r332;
	bra.uni 	BB4_113;

BB4_5:
	setp.gt.s32	%p11, %r15, 8;
	@%p11 bra 	BB4_38;

	setp.gt.s32	%p24, %r15, 3;
	@%p24 bra 	BB4_22;

	setp.gt.s32	%p31, %r15, 1;
	@%p31 bra 	BB4_15;

	setp.eq.s32	%p34, %r15, 0;
	@%p34 bra 	BB4_107;
	bra.uni 	BB4_9;

BB4_107:
	mov.u32 	%r352, 0;
	setp.lt.s32	%p109, %r105, 1;
	@%p109 bra 	BB4_113;

	mov.u32 	%r351, 0;
	setp.lt.s32	%p110, %r2, 1;
	@%p110 bra 	BB4_111;

BB4_109:
	.pragma "nounroll";
	// inline asm
	{add.f16 %rs345,%rs457,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs348,%rs345,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs351,%rs348,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs354,%rs351,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs357,%rs354,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs360,%rs357,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs363,%rs360,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs366,%rs363,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs369,%rs366,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs372,%rs369,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs375,%rs372,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs378,%rs375,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs381,%rs378,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs384,%rs381,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs387,%rs384,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs390,%rs387,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs393,%rs390,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs396,%rs393,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs399,%rs396,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs402,%rs399,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs405,%rs402,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs408,%rs405,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs411,%rs408,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs414,%rs411,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs417,%rs414,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs420,%rs417,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs423,%rs420,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs426,%rs423,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs429,%rs426,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs432,%rs429,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs435,%rs432,%rs34;
}
	// inline asm
	// inline asm
	{add.f16 %rs457,%rs435,%rs34;
}
	// inline asm
	add.s32 	%r351, %r351, 32;
	setp.ne.s32	%p111, %r351, %r2;
	@%p111 bra 	BB4_109;

	setp.eq.s32	%p112, %r2, %r105;
	mov.u32 	%r351, %r2;
	@%p112 bra 	BB4_112;

BB4_111:
	.pragma "nounroll";
	// inline asm
	{add.f16 %rs457,%rs457,%rs34;
}
	// inline asm
	add.s32 	%r351, %r351, 1;
	setp.ne.s32	%p113, %r351, %r105;
	@%p113 bra 	BB4_111;
	bra.uni 	BB4_112;

BB4_38:
	setp.gt.s32	%p12, %r15, 12;
	@%p12 bra 	BB4_51;

	setp.gt.s32	%p19, %r15, 10;
	@%p19 bra 	BB4_47;

	setp.eq.s32	%p22, %r15, 9;
	@%p22 bra 	BB4_80;
	bra.uni 	BB4_41;

BB4_80:
	mov.u32 	%r352, 0;
	setp.lt.s32	%p64, %r105, 1;
	@%p64 bra 	BB4_81;

	mov.u32 	%r331, 0;
	setp.lt.s32	%p65, %r2, 1;
	mov.u32 	%r332, %r104;
	@%p65 bra 	BB4_85;

BB4_83:
	.pragma "nounroll";
	mul.lo.s32 	%r153, %r332, %r104;
	mul.lo.s32 	%r154, %r153, %r104;
	mul.lo.s32 	%r155, %r154, %r104;
	mul.lo.s32 	%r156, %r155, %r104;
	mul.lo.s32 	%r157, %r156, %r104;
	mul.lo.s32 	%r158, %r157, %r104;
	mul.lo.s32 	%r159, %r158, %r104;
	mul.lo.s32 	%r160, %r159, %r104;
	mul.lo.s32 	%r161, %r160, %r104;
	mul.lo.s32 	%r162, %r161, %r104;
	mul.lo.s32 	%r163, %r162, %r104;
	mul.lo.s32 	%r164, %r163, %r104;
	mul.lo.s32 	%r165, %r164, %r104;
	mul.lo.s32 	%r166, %r165, %r104;
	mul.lo.s32 	%r167, %r166, %r104;
	mul.lo.s32 	%r168, %r167, %r104;
	mul.lo.s32 	%r169, %r168, %r104;
	mul.lo.s32 	%r170, %r169, %r104;
	mul.lo.s32 	%r171, %r170, %r104;
	mul.lo.s32 	%r172, %r171, %r104;
	mul.lo.s32 	%r173, %r172, %r104;
	mul.lo.s32 	%r174, %r173, %r104;
	mul.lo.s32 	%r175, %r174, %r104;
	mul.lo.s32 	%r176, %r175, %r104;
	mul.lo.s32 	%r177, %r176, %r104;
	mul.lo.s32 	%r178, %r177, %r104;
	mul.lo.s32 	%r179, %r178, %r104;
	mul.lo.s32 	%r180, %r179, %r104;
	mul.lo.s32 	%r181, %r180, %r104;
	mul.lo.s32 	%r182, %r181, %r104;
	mul.lo.s32 	%r183, %r182, %r104;
	mul.lo.s32 	%r332, %r183, %r104;
	add.s32 	%r331, %r331, 32;
	setp.ne.s32	%p66, %r331, %r2;
	@%p66 bra 	BB4_83;

	setp.eq.s32	%p67, %r2, %r105;
	mov.u32 	%r331, %r2;
	@%p67 bra 	BB4_112;

BB4_85:
	.pragma "nounroll";
	mul.lo.s32 	%r332, %r332, %r104;
	add.s32 	%r331, %r331, 1;
	setp.eq.s32	%p68, %r331, %r105;
	@%p68 bra 	BB4_112;
	bra.uni 	BB4_85;

BB4_22:
	setp.gt.s32	%p25, %r15, 5;
	@%p25 bra 	BB4_30;

	setp.eq.s32	%p29, %r15, 4;
	@%p29 bra 	BB4_97;
	bra.uni 	BB4_24;

BB4_97:
	mov.u32 	%r352, 0;
	setp.lt.s32	%p89, %r105, 1;
	@%p89 bra 	BB4_113;

	mov.u32 	%r343, 0;
	setp.lt.s32	%p90, %r2, 1;
	@%p90 bra 	BB4_101;

BB4_99:
	.pragma "nounroll";
	add.f64 	%fd49, %fd95, 0d3FF199999999999A;
	add.f64 	%fd50, %fd49, 0d3FF199999999999A;
	add.f64 	%fd51, %fd50, 0d3FF199999999999A;
	add.f64 	%fd52, %fd51, 0d3FF199999999999A;
	add.f64 	%fd53, %fd52, 0d3FF199999999999A;
	add.f64 	%fd54, %fd53, 0d3FF199999999999A;
	add.f64 	%fd55, %fd54, 0d3FF199999999999A;
	add.f64 	%fd56, %fd55, 0d3FF199999999999A;
	add.f64 	%fd57, %fd56, 0d3FF199999999999A;
	add.f64 	%fd58, %fd57, 0d3FF199999999999A;
	add.f64 	%fd59, %fd58, 0d3FF199999999999A;
	add.f64 	%fd60, %fd59, 0d3FF199999999999A;
	add.f64 	%fd61, %fd60, 0d3FF199999999999A;
	add.f64 	%fd62, %fd61, 0d3FF199999999999A;
	add.f64 	%fd63, %fd62, 0d3FF199999999999A;
	add.f64 	%fd64, %fd63, 0d3FF199999999999A;
	add.f64 	%fd65, %fd64, 0d3FF199999999999A;
	add.f64 	%fd66, %fd65, 0d3FF199999999999A;
	add.f64 	%fd67, %fd66, 0d3FF199999999999A;
	add.f64 	%fd68, %fd67, 0d3FF199999999999A;
	add.f64 	%fd69, %fd68, 0d3FF199999999999A;
	add.f64 	%fd70, %fd69, 0d3FF199999999999A;
	add.f64 	%fd71, %fd70, 0d3FF199999999999A;
	add.f64 	%fd72, %fd71, 0d3FF199999999999A;
	add.f64 	%fd73, %fd72, 0d3FF199999999999A;
	add.f64 	%fd74, %fd73, 0d3FF199999999999A;
	add.f64 	%fd75, %fd74, 0d3FF199999999999A;
	add.f64 	%fd76, %fd75, 0d3FF199999999999A;
	add.f64 	%fd77, %fd76, 0d3FF199999999999A;
	add.f64 	%fd78, %fd77, 0d3FF199999999999A;
	add.f64 	%fd79, %fd78, 0d3FF199999999999A;
	add.f64 	%fd95, %fd79, 0d3FF199999999999A;
	add.s32 	%r343, %r343, 32;
	setp.ne.s32	%p91, %r343, %r2;
	@%p91 bra 	BB4_99;

	setp.eq.s32	%p92, %r2, %r105;
	mov.u32 	%r343, %r2;
	@%p92 bra 	BB4_112;

BB4_101:
	.pragma "nounroll";
	add.f64 	%fd95, %fd95, 0d3FF199999999999A;
	add.s32 	%r343, %r343, 1;
	setp.eq.s32	%p93, %r343, %r105;
	@%p93 bra 	BB4_112;
	bra.uni 	BB4_101;

BB4_51:
	setp.gt.s32	%p13, %r15, 14;
	@%p13 bra 	BB4_55;

	setp.eq.s32	%p17, %r15, 13;
	@%p17 bra 	BB4_72;
	bra.uni 	BB4_53;

BB4_72:
	mov.u32 	%r354, 931383626;
	mov.u32 	%r352, 0;
	setp.lt.s32	%p50, %r105, 1;
	@%p50 bra 	BB4_113;

BB4_73:
	brev.b32 	%r354, %r354;
	add.s32 	%r352, %r352, 1;
	setp.eq.s32	%p51, %r352, %r105;
	@%p51 bra 	BB4_112;
	bra.uni 	BB4_73;

BB4_15:
	setp.eq.s32	%p32, %r15, 2;
	@%p32 bra 	BB4_102;
	bra.uni 	BB4_16;

BB4_102:
	mov.u32 	%r352, 0;
	setp.lt.s32	%p99, %r105, 1;
	@%p99 bra 	BB4_113;

	mov.u32 	%r347, 0;
	setp.lt.s32	%p100, %r2, 1;
	@%p100 bra 	BB4_106;

BB4_104:
	.pragma "nounroll";
	add.f32 	%f101, %f142, 0f3F8CCCCD;
	add.f32 	%f102, %f101, 0f3F8CCCCD;
	add.f32 	%f103, %f102, 0f3F8CCCCD;
	add.f32 	%f104, %f103, 0f3F8CCCCD;
	add.f32 	%f105, %f104, 0f3F8CCCCD;
	add.f32 	%f106, %f105, 0f3F8CCCCD;
	add.f32 	%f107, %f106, 0f3F8CCCCD;
	add.f32 	%f108, %f107, 0f3F8CCCCD;
	add.f32 	%f109, %f108, 0f3F8CCCCD;
	add.f32 	%f110, %f109, 0f3F8CCCCD;
	add.f32 	%f111, %f110, 0f3F8CCCCD;
	add.f32 	%f112, %f111, 0f3F8CCCCD;
	add.f32 	%f113, %f112, 0f3F8CCCCD;
	add.f32 	%f114, %f113, 0f3F8CCCCD;
	add.f32 	%f115, %f114, 0f3F8CCCCD;
	add.f32 	%f116, %f115, 0f3F8CCCCD;
	add.f32 	%f117, %f116, 0f3F8CCCCD;
	add.f32 	%f118, %f117, 0f3F8CCCCD;
	add.f32 	%f119, %f118, 0f3F8CCCCD;
	add.f32 	%f120, %f119, 0f3F8CCCCD;
	add.f32 	%f121, %f120, 0f3F8CCCCD;
	add.f32 	%f122, %f121, 0f3F8CCCCD;
	add.f32 	%f123, %f122, 0f3F8CCCCD;
	add.f32 	%f124, %f123, 0f3F8CCCCD;
	add.f32 	%f125, %f124, 0f3F8CCCCD;
	add.f32 	%f126, %f125, 0f3F8CCCCD;
	add.f32 	%f127, %f126, 0f3F8CCCCD;
	add.f32 	%f128, %f127, 0f3F8CCCCD;
	add.f32 	%f129, %f128, 0f3F8CCCCD;
	add.f32 	%f130, %f129, 0f3F8CCCCD;
	add.f32 	%f131, %f130, 0f3F8CCCCD;
	add.f32 	%f142, %f131, 0f3F8CCCCD;
	add.s32 	%r347, %r347, 32;
	setp.ne.s32	%p101, %r347, %r2;
	@%p101 bra 	BB4_104;

	setp.eq.s32	%p102, %r2, %r105;
	mov.u32 	%r347, %r2;
	@%p102 bra 	BB4_112;

BB4_106:
	.pragma "nounroll";
	add.f32 	%f142, %f142, 0f3F8CCCCD;
	add.s32 	%r347, %r347, 1;
	setp.eq.s32	%p103, %r347, %r105;
	@%p103 bra 	BB4_112;
	bra.uni 	BB4_106;

BB4_47:
	setp.eq.s32	%p20, %r15, 11;
	@%p20 bra 	BB4_74;
	bra.uni 	BB4_48;

BB4_74:
	mov.u32 	%r352, 0;
	setp.lt.s32	%p54, %r105, 1;
	@%p54 bra 	BB4_75;

	mov.u32 	%r325, 0;
	setp.lt.s32	%p55, %r2, 1;
	mov.u64 	%rd164, %rd1;
	@%p55 bra 	BB4_79;

BB4_77:
	.pragma "nounroll";
	mul.lo.s64 	%rd24, %rd164, %rd1;
	mul.lo.s64 	%rd25, %rd24, %rd1;
	mul.lo.s64 	%rd26, %rd25, %rd1;
	mul.lo.s64 	%rd27, %rd26, %rd1;
	mul.lo.s64 	%rd28, %rd27, %rd1;
	mul.lo.s64 	%rd29, %rd28, %rd1;
	mul.lo.s64 	%rd30, %rd29, %rd1;
	mul.lo.s64 	%rd31, %rd30, %rd1;
	mul.lo.s64 	%rd32, %rd31, %rd1;
	mul.lo.s64 	%rd33, %rd32, %rd1;
	mul.lo.s64 	%rd34, %rd33, %rd1;
	mul.lo.s64 	%rd35, %rd34, %rd1;
	mul.lo.s64 	%rd36, %rd35, %rd1;
	mul.lo.s64 	%rd37, %rd36, %rd1;
	mul.lo.s64 	%rd38, %rd37, %rd1;
	mul.lo.s64 	%rd39, %rd38, %rd1;
	mul.lo.s64 	%rd40, %rd39, %rd1;
	mul.lo.s64 	%rd41, %rd40, %rd1;
	mul.lo.s64 	%rd42, %rd41, %rd1;
	mul.lo.s64 	%rd43, %rd42, %rd1;
	mul.lo.s64 	%rd44, %rd43, %rd1;
	mul.lo.s64 	%rd45, %rd44, %rd1;
	mul.lo.s64 	%rd46, %rd45, %rd1;
	mul.lo.s64 	%rd47, %rd46, %rd1;
	mul.lo.s64 	%rd48, %rd47, %rd1;
	mul.lo.s64 	%rd49, %rd48, %rd1;
	mul.lo.s64 	%rd50, %rd49, %rd1;
	mul.lo.s64 	%rd51, %rd50, %rd1;
	mul.lo.s64 	%rd52, %rd51, %rd1;
	mul.lo.s64 	%rd53, %rd52, %rd1;
	mul.lo.s64 	%rd54, %rd53, %rd1;
	mul.lo.s64 	%rd164, %rd54, %rd1;
	add.s32 	%r325, %r325, 32;
	setp.ne.s32	%p56, %r325, %r2;
	@%p56 bra 	BB4_77;

	setp.eq.s32	%p57, %r2, %r105;
	mov.u32 	%r325, %r2;
	@%p57 bra 	BB4_112;

BB4_79:
	.pragma "nounroll";
	mul.lo.s64 	%rd164, %rd164, %rd1;
	add.s32 	%r325, %r325, 1;
	setp.eq.s32	%p58, %r325, %r105;
	@%p58 bra 	BB4_112;
	bra.uni 	BB4_79;

BB4_30:
	setp.eq.s32	%p26, %r15, 6;
	@%p26 bra 	BB4_92;

	setp.eq.s32	%p27, %r15, 7;
	@%p27 bra 	BB4_86;
	bra.uni 	BB4_32;

BB4_86:
	mov.u32 	%r352, 0;
	setp.lt.s32	%p74, %r105, 1;
	@%p74 bra 	BB4_87;

	mov.u32 	%r337, 0;
	setp.lt.s32	%p75, %r2, 1;
	mov.u16 	%rs451, %rs4;
	@%p75 bra 	BB4_91;

BB4_89:
	.pragma "nounroll";
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	add.s32 	%r337, %r337, 32;
	setp.ne.s32	%p76, %r337, %r2;
	@%p76 bra 	BB4_89;

	setp.eq.s32	%p77, %r2, %r105;
	mov.u32 	%r337, %r2;
	@%p77 bra 	BB4_112;

BB4_91:
	.pragma "nounroll";
	// inline asm
	mul.lo.s16 %rs451, %rs451, %rs4;
	// inline asm
	add.s32 	%r337, %r337, 1;
	setp.eq.s32	%p78, %r337, %r105;
	@%p78 bra 	BB4_112;
	bra.uni 	BB4_91;

BB4_55:
	setp.eq.s32	%p14, %r15, 15;
	@%p14 bra 	BB4_64;

	setp.eq.s32	%p15, %r15, 16;
	@%p15 bra 	BB4_62;
	bra.uni 	BB4_57;

BB4_62:
	mov.u32 	%r354, 931383626;
	mov.u32 	%r352, 0;
	setp.lt.s32	%p41, %r105, 1;
	@%p41 bra 	BB4_113;

BB4_63:
	popc.b32 	%r354, %r354;
	add.s32 	%r352, %r352, 1;
	setp.eq.s32	%p42, %r352, %r105;
	@%p42 bra 	BB4_112;
	bra.uni 	BB4_63;

BB4_9:
	setp.eq.s32	%p35, %r15, 1;
	@%p35 bra 	BB4_10;
	bra.uni 	BB4_54;

BB4_10:
	mov.u32 	%r352, 0;
	mov.f32 	%f132, 0f3F800000;
	// inline asm
	{  cvt.rn.f16.f32 %rs457, %f132;}

	// inline asm
	setp.lt.s32	%p104, %r105, 1;
	@%p104 bra 	BB4_113;

	mov.u32 	%r349, 0;
	setp.lt.s32	%p105, %r2, 1;
	@%p105 bra 	BB4_14;

BB4_12:
	.pragma "nounroll";
	// inline asm
	{mul.f16 %rs246,%rs457,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs249,%rs246,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs252,%rs249,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs255,%rs252,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs258,%rs255,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs261,%rs258,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs264,%rs261,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs267,%rs264,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs270,%rs267,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs273,%rs270,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs276,%rs273,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs279,%rs276,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs282,%rs279,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs285,%rs282,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs288,%rs285,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs291,%rs288,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs294,%rs291,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs297,%rs294,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs300,%rs297,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs303,%rs300,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs306,%rs303,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs309,%rs306,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs312,%rs309,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs315,%rs312,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs318,%rs315,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs321,%rs318,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs324,%rs321,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs327,%rs324,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs330,%rs327,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs333,%rs330,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs336,%rs333,%rs35;
}
	// inline asm
	// inline asm
	{mul.f16 %rs457,%rs336,%rs35;
}
	// inline asm
	add.s32 	%r349, %r349, 32;
	setp.ne.s32	%p106, %r349, %r2;
	@%p106 bra 	BB4_12;

	setp.eq.s32	%p107, %r2, %r105;
	mov.u32 	%r349, %r2;
	@%p107 bra 	BB4_112;

BB4_14:
	.pragma "nounroll";
	// inline asm
	{mul.f16 %rs457,%rs457,%rs35;
}
	// inline asm
	add.s32 	%r349, %r349, 1;
	setp.eq.s32	%p108, %r349, %r105;
	@%p108 bra 	BB4_112;
	bra.uni 	BB4_14;

BB4_41:
	setp.eq.s32	%p23, %r15, 10;
	@%p23 bra 	BB4_42;
	bra.uni 	BB4_54;

BB4_42:
	mov.u32 	%r352, 0;
	setp.lt.s32	%p59, %r105, 1;
	@%p59 bra 	BB4_113;

	mov.u32 	%r327, 0;
	setp.lt.s32	%p60, %r2, 1;
	@%p60 bra 	BB4_46;

BB4_44:
	.pragma "nounroll";
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	add.s32 	%r327, %r327, 32;
	setp.ne.s32	%p61, %r327, %r2;
	@%p61 bra 	BB4_44;

	setp.eq.s32	%p62, %r2, %r105;
	mov.u32 	%r327, %r2;
	@%p62 bra 	BB4_112;

BB4_46:
	.pragma "nounroll";
	// inline asm
	add.s64 %rd164, %rd164, %rd1;
	// inline asm
	add.s32 	%r327, %r327, 1;
	setp.eq.s32	%p63, %r327, %r105;
	@%p63 bra 	BB4_112;
	bra.uni 	BB4_46;

BB4_24:
	setp.eq.s32	%p30, %r15, 5;
	@%p30 bra 	BB4_25;
	bra.uni 	BB4_54;

BB4_25:
	mov.f64 	%fd95, 0d3FF0000000000000;
	mov.u32 	%r352, 0;
	setp.lt.s32	%p84, %r105, 1;
	@%p84 bra 	BB4_113;

	mov.u32 	%r341, 0;
	mov.f64 	%fd95, 0d3FF0000000000000;
	setp.lt.s32	%p85, %r2, 1;
	@%p85 bra 	BB4_29;

BB4_27:
	.pragma "nounroll";
	mul.f64 	%fd18, %fd95, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd19, %fd18, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd20, %fd19, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd21, %fd20, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd22, %fd21, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd23, %fd22, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd24, %fd23, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd25, %fd24, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd26, %fd25, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd27, %fd26, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd28, %fd27, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd29, %fd28, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd30, %fd29, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd31, %fd30, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd32, %fd31, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd33, %fd32, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd34, %fd33, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd35, %fd34, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd36, %fd35, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd37, %fd36, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd38, %fd37, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd39, %fd38, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd40, %fd39, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd41, %fd40, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd42, %fd41, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd43, %fd42, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd44, %fd43, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd45, %fd44, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd46, %fd45, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd47, %fd46, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd48, %fd47, 0d3FF4CCCCCCCCCCCD;
	mul.f64 	%fd95, %fd48, 0d3FF4CCCCCCCCCCCD;
	add.s32 	%r341, %r341, 32;
	setp.ne.s32	%p86, %r341, %r2;
	@%p86 bra 	BB4_27;

	setp.eq.s32	%p87, %r2, %r105;
	mov.u32 	%r341, %r2;
	@%p87 bra 	BB4_112;

BB4_29:
	.pragma "nounroll";
	mul.f64 	%fd95, %fd95, 0d3FF4CCCCCCCCCCCD;
	add.s32 	%r341, %r341, 1;
	setp.eq.s32	%p88, %r341, %r105;
	@%p88 bra 	BB4_112;
	bra.uni 	BB4_29;

BB4_53:
	setp.eq.s32	%p18, %r15, 14;
	@%p18 bra 	BB4_67;
	bra.uni 	BB4_54;

BB4_67:
	mov.f32 	%f142, 0f41B80000;
	mov.u32 	%r352, 0;
	setp.lt.s32	%p45, %r105, 1;
	@%p45 bra 	BB4_113;

	mov.u32 	%r319, 0;
	mov.f32 	%f142, 0f41B80000;
	setp.lt.s32	%p46, %r2, 1;
	@%p46 bra 	BB4_71;

BB4_69:
	.pragma "nounroll";
	rcp.rp.f32 	%f36, %f142;
	rcp.rp.f32 	%f37, %f36;
	rcp.rp.f32 	%f38, %f37;
	rcp.rp.f32 	%f39, %f38;
	rcp.rp.f32 	%f40, %f39;
	rcp.rp.f32 	%f41, %f40;
	rcp.rp.f32 	%f42, %f41;
	rcp.rp.f32 	%f43, %f42;
	rcp.rp.f32 	%f44, %f43;
	rcp.rp.f32 	%f45, %f44;
	rcp.rp.f32 	%f46, %f45;
	rcp.rp.f32 	%f47, %f46;
	rcp.rp.f32 	%f48, %f47;
	rcp.rp.f32 	%f49, %f48;
	rcp.rp.f32 	%f50, %f49;
	rcp.rp.f32 	%f51, %f50;
	rcp.rp.f32 	%f52, %f51;
	rcp.rp.f32 	%f53, %f52;
	rcp.rp.f32 	%f54, %f53;
	rcp.rp.f32 	%f55, %f54;
	rcp.rp.f32 	%f56, %f55;
	rcp.rp.f32 	%f57, %f56;
	rcp.rp.f32 	%f58, %f57;
	rcp.rp.f32 	%f59, %f58;
	rcp.rp.f32 	%f60, %f59;
	rcp.rp.f32 	%f61, %f60;
	rcp.rp.f32 	%f62, %f61;
	rcp.rp.f32 	%f63, %f62;
	rcp.rp.f32 	%f64, %f63;
	rcp.rp.f32 	%f65, %f64;
	rcp.rp.f32 	%f66, %f65;
	rcp.rp.f32 	%f142, %f66;
	add.s32 	%r319, %r319, 32;
	setp.ne.s32	%p47, %r319, %r2;
	@%p47 bra 	BB4_69;

	setp.eq.s32	%p48, %r2, %r105;
	mov.u32 	%r319, %r2;
	@%p48 bra 	BB4_112;

BB4_71:
	.pragma "nounroll";
	rcp.rp.f32 	%f142, %f142;
	add.s32 	%r319, %r319, 1;
	setp.eq.s32	%p49, %r319, %r105;
	@%p49 bra 	BB4_112;
	bra.uni 	BB4_71;

BB4_16:
	setp.eq.s32	%p33, %r15, 3;
	@%p33 bra 	BB4_17;
	bra.uni 	BB4_54;

BB4_17:
	mov.f32 	%f142, 0f3F800000;
	mov.u32 	%r352, 0;
	setp.lt.s32	%p94, %r105, 1;
	@%p94 bra 	BB4_113;

	mov.u32 	%r345, 0;
	mov.f32 	%f142, 0f3F800000;
	setp.lt.s32	%p95, %r2, 1;
	@%p95 bra 	BB4_21;

BB4_19:
	.pragma "nounroll";
	mul.f32 	%f70, %f142, 0f3FA66666;
	mul.f32 	%f71, %f70, 0f3FA66666;
	mul.f32 	%f72, %f71, 0f3FA66666;
	mul.f32 	%f73, %f72, 0f3FA66666;
	mul.f32 	%f74, %f73, 0f3FA66666;
	mul.f32 	%f75, %f74, 0f3FA66666;
	mul.f32 	%f76, %f75, 0f3FA66666;
	mul.f32 	%f77, %f76, 0f3FA66666;
	mul.f32 	%f78, %f77, 0f3FA66666;
	mul.f32 	%f79, %f78, 0f3FA66666;
	mul.f32 	%f80, %f79, 0f3FA66666;
	mul.f32 	%f81, %f80, 0f3FA66666;
	mul.f32 	%f82, %f81, 0f3FA66666;
	mul.f32 	%f83, %f82, 0f3FA66666;
	mul.f32 	%f84, %f83, 0f3FA66666;
	mul.f32 	%f85, %f84, 0f3FA66666;
	mul.f32 	%f86, %f85, 0f3FA66666;
	mul.f32 	%f87, %f86, 0f3FA66666;
	mul.f32 	%f88, %f87, 0f3FA66666;
	mul.f32 	%f89, %f88, 0f3FA66666;
	mul.f32 	%f90, %f89, 0f3FA66666;
	mul.f32 	%f91, %f90, 0f3FA66666;
	mul.f32 	%f92, %f91, 0f3FA66666;
	mul.f32 	%f93, %f92, 0f3FA66666;
	mul.f32 	%f94, %f93, 0f3FA66666;
	mul.f32 	%f95, %f94, 0f3FA66666;
	mul.f32 	%f96, %f95, 0f3FA66666;
	mul.f32 	%f97, %f96, 0f3FA66666;
	mul.f32 	%f98, %f97, 0f3FA66666;
	mul.f32 	%f99, %f98, 0f3FA66666;
	mul.f32 	%f100, %f99, 0f3FA66666;
	mul.f32 	%f142, %f100, 0f3FA66666;
	add.s32 	%r345, %r345, 32;
	setp.ne.s32	%p96, %r345, %r2;
	@%p96 bra 	BB4_19;

	setp.eq.s32	%p97, %r2, %r105;
	mov.u32 	%r345, %r2;
	@%p97 bra 	BB4_112;

BB4_21:
	.pragma "nounroll";
	mul.f32 	%f142, %f142, 0f3FA66666;
	add.s32 	%r345, %r345, 1;
	setp.eq.s32	%p98, %r345, %r105;
	@%p98 bra 	BB4_112;
	bra.uni 	BB4_21;

BB4_48:
	setp.eq.s32	%p21, %r15, 12;
	@%p21 bra 	BB4_49;
	bra.uni 	BB4_54;

BB4_49:
	mov.u32 	%r332, 931383626;
	mov.u32 	%r352, 0;
	setp.lt.s32	%p52, %r105, 1;
	@%p52 bra 	BB4_113;

BB4_50:
	and.b32  	%r332, %r332, -882647319;
	add.s32 	%r352, %r352, 1;
	setp.eq.s32	%p53, %r352, %r105;
	@%p53 bra 	BB4_112;
	bra.uni 	BB4_50;

BB4_92:
	mov.u32 	%r352, 0;
	setp.lt.s32	%p79, %r105, 1;
	@%p79 bra 	BB4_113;

	mov.u32 	%r339, 0;
	setp.lt.s32	%p80, %r2, 1;
	@%p80 bra 	BB4_96;

BB4_94:
	.pragma "nounroll";
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	add.s32 	%r339, %r339, 32;
	setp.ne.s32	%p81, %r339, %r2;
	@%p81 bra 	BB4_94;

	setp.eq.s32	%p82, %r2, %r105;
	mov.u32 	%r339, %r2;
	@%p82 bra 	BB4_112;

BB4_96:
	.pragma "nounroll";
	// inline asm
	add.s16 %rs451, %rs451, %rs4;
	// inline asm
	add.s32 	%r339, %r339, 1;
	setp.eq.s32	%p83, %r339, %r105;
	@%p83 bra 	BB4_112;
	bra.uni 	BB4_96;

BB4_32:
	setp.eq.s32	%p28, %r15, 8;
	@%p28 bra 	BB4_33;
	bra.uni 	BB4_54;

BB4_33:
	mov.u32 	%r352, 0;
	setp.lt.s32	%p69, %r105, 1;
	@%p69 bra 	BB4_113;

	mov.u32 	%r335, 0;
	setp.lt.s32	%p70, %r2, 1;
	@%p70 bra 	BB4_37;

BB4_35:
	.pragma "nounroll";
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	add.s32 	%r335, %r335, 32;
	setp.ne.s32	%p71, %r335, %r2;
	@%p71 bra 	BB4_35;

	setp.eq.s32	%p72, %r2, %r105;
	mov.u32 	%r335, %r2;
	@%p72 bra 	BB4_112;

BB4_37:
	.pragma "nounroll";
	// inline asm
	add.s32 %r332, %r332, %r104;
	// inline asm
	add.s32 	%r335, %r335, 1;
	setp.eq.s32	%p73, %r335, %r105;
	@%p73 bra 	BB4_112;
	bra.uni 	BB4_37;

BB4_64:
	mov.u32 	%r332, 0;
	setp.lt.s32	%p43, %r105, 1;
	mov.u32 	%r317, %r332;
	@%p43 bra 	BB4_65;

BB4_66:
	clz.b32 	%r332, %r332;
	add.s32 	%r317, %r317, 1;
	setp.eq.s32	%p44, %r317, %r105;
	@%p44 bra 	BB4_112;
	bra.uni 	BB4_66;

BB4_57:
	setp.ne.s32	%p16, %r15, 17;
	@%p16 bra 	BB4_54;

	mov.u32 	%r352, 0;
	mov.u32 	%r122, 1;
	// inline asm
	cvt.rn.f16.s32 %rs457, %r122;
	// inline asm
	setp.lt.s32	%p36, %r105, 1;
	@%p36 bra 	BB4_113;

BB4_59:
	mov.f64 	%fd14, 0d3FEF0A3D70A3D70A;
	// inline asm
	{  cvt.rn.f16.f64 %rs39, %fd14;}

	// inline asm
	// inline asm
	{  cvt.f32.f16 %f25, %rs457;}

	// inline asm
	// inline asm
	{  cvt.f32.f16 %f26, %rs39;}

	// inline asm
	// inline asm
	{rcp.approx.ftz.f32 %f27, %f26;
}
	// inline asm
	mul.f32 	%f29, %f25, %f27;
	// inline asm
	{  cvt.rn.f16.f32 %rs457, %f29;}

	// inline asm
	and.b16  	%rs44, %rs457, 32767;
	mov.u16 	%rs45, 143;
	// inline asm
	{ .reg .pred __$temp3;
  setp.lt.f16  __$temp3, %rs44, %rs45;
  selp.u16 %rs43, 1, 0, __$temp3;}
	// inline asm
	setp.ne.s16	%p37, %rs43, 0;
	setp.ne.s16	%p38, %rs44, 0;
	and.pred  	%p39, %p38, %p37;
	@!%p39 bra 	BB4_61;
	bra.uni 	BB4_60;

BB4_60:
	neg.f32 	%f31, %f26;
	fma.rn.f32 	%f32, %f31, %f29, %f25;
	fma.rn.f32 	%f30, %f27, %f32, %f29;
	// inline asm
	{  cvt.rn.f16.f32 %rs457, %f30;}

	// inline asm

BB4_61:
	add.s32 	%r352, %r352, 1;
	setp.eq.s32	%p40, %r352, %r105;
	@%p40 bra 	BB4_112;
	bra.uni 	BB4_59;

BB4_112:
	mov.u32 	%r352, %r105;

BB4_113:
	// inline asm
	mov.u64 %rd154, %globaltimer;
	// inline asm
	st.shared.u64 	[clock_now], %rd154;
	ld.shared.u64 	%rd155, [clock_begin];
	sub.s64 	%rd156, %rd154, %rd155;
	setp.lt.u64	%p114, %rd156, %rd2;
	@%p114 bra 	BB4_5;

BB4_114:
	ld.param.u64 	%rd160, [_Z13computeKernelPPjPiiyiiiii_param_1];
	cvta.to.global.u64 	%rd14, %rd160;
	// inline asm
	{  cvt.f32.f16 %f133, %rs457;}

	// inline asm
	add.f32 	%f134, %f142, %f133;
	cvt.f64.f32	%fd80, %f134;
	add.f64 	%fd81, %fd95, %fd80;
	cvt.rn.f64.s16	%fd82, %rs451;
	add.f64 	%fd83, %fd82, %fd81;
	cvt.rn.f64.s32	%fd84, %r332;
	add.f64 	%fd85, %fd84, %fd83;
	cvt.rn.f64.s64	%fd86, %rd164;
	add.f64 	%fd87, %fd86, %fd85;
	cvt.rn.f64.u32	%fd88, %r354;
	add.f64 	%fd89, %fd88, %fd87;
	cvt.rzi.u32.f64	%r102, %fd89;
	bar.sync 	0;
	st.global.u32 	[%rd14+4], %r352;
	st.global.u32 	[%rd14+8], %r102;
	st.global.u32 	[%rd14+12], %r102;
	bra.uni 	BB4_115;

BB4_54:
	mov.u64 	%rd157, $str$10;
	cvta.global.u64 	%rd158, %rd157;
	mov.u64 	%rd159, 0;
	// Callseq Start 10
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd158;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd159;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r310, [retval0+0];
	
	//{
	}// Callseq End 10

BB4_115:
	ret;
}

	// .globl	_Z12memoryKernelPPjPiiyiS_
.visible .entry _Z12memoryKernelPPjPiiyiS_(
	.param .u64 _Z12memoryKernelPPjPiiyiS__param_0,
	.param .u64 _Z12memoryKernelPPjPiiyiS__param_1,
	.param .u32 _Z12memoryKernelPPjPiiyiS__param_2,
	.param .u64 _Z12memoryKernelPPjPiiyiS__param_3,
	.param .u32 _Z12memoryKernelPPjPiiyiS__param_4,
	.param .u64 _Z12memoryKernelPPjPiiyiS__param_5
)
{



	ret;
}


