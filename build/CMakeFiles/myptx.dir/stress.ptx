//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-29069683
// Cuda compilation tools, release 11.1, V11.1.74
// Based on LLVM 3.4svn
//

.version 7.1
.target sm_61
.address_size 64

	// .globl	_Z10testKernelPPjPt
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.global .align 1 .b8 $str[12] = {99, 121, 99, 108, 101, 115, 32, 37, 108, 117, 10, 0};

.visible .entry _Z10testKernelPPjPt(
	.param .u64 _Z10testKernelPPjPt_param_0,
	.param .u64 _Z10testKernelPPjPt_param_1
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<39>;
	.reg .b64 	%rd<29>;


	ld.param.u64 	%rd14, [_Z10testKernelPPjPt_param_0];
	ld.param.u64 	%rd15, [_Z10testKernelPPjPt_param_1];
	cvta.to.global.u64 	%rd28, %rd15;
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %tid.y;
	mov.u32 	%r6, %tid.x;
	mad.lo.s32 	%r7, %r4, %r5, %r6;
	shr.s32 	%r8, %r7, 31;
	shr.u32 	%r9, %r8, 27;
	add.s32 	%r10, %r7, %r9;
	shr.s32 	%r11, %r10, 5;
	cvta.to.global.u64 	%rd16, %rd14;
	ld.global.u64 	%rd17, [%rd16];
	cvta.to.global.u64 	%rd2, %rd17;
	mov.u32 	%r12, %nctaid.x;
	mov.u32 	%r13, %ctaid.y;
	mul.lo.s32 	%r14, %r12, %r13;
	mov.u32 	%r15, %ctaid.x;
	shl.b32 	%r16, %r15, 13;
	mad.lo.s32 	%r17, %r14, 8192, %r16;
	mad.lo.s32 	%r18, %r11, 2048, %r17;
	cvt.s64.s32	%rd18, %r18;
	mul.wide.s32 	%rd3, %r18, 2;
	neg.s64 	%rd27, %rd18;
	add.s64 	%rd5, %rd2, 4;
	add.s32 	%r19, %r15, %r14;
	mad.lo.s32 	%r20, %r19, 4, %r11;
	shl.b32 	%r21, %r20, 11;
	cvt.s64.s32	%rd19, %r21;
	mul.wide.s32 	%rd6, %r21, 2;
	neg.s64 	%rd26, %rd19;
	mov.u32 	%r38, -2048;

BB0_1:
	shl.b64 	%rd20, %rd26, 2;
	sub.s64 	%rd21, %rd2, %rd20;
	ld.global.u32 	%r22, [%rd21];
	add.s64 	%rd22, %rd28, %rd6;
	st.global.u16 	[%rd22], %r22;
	shl.b64 	%rd23, %rd27, 2;
	sub.s64 	%rd24, %rd5, %rd23;
	ld.global.u32 	%r23, [%rd24];
	add.s64 	%rd25, %rd28, %rd3;
	st.global.u16 	[%rd25+2], %r23;
	ld.global.u32 	%r24, [%rd24+4];
	st.global.u16 	[%rd25+4], %r24;
	ld.global.u32 	%r25, [%rd24+8];
	st.global.u16 	[%rd25+6], %r25;
	ld.global.u32 	%r26, [%rd24+12];
	st.global.u16 	[%rd25+8], %r26;
	ld.global.u32 	%r27, [%rd24+16];
	st.global.u16 	[%rd25+10], %r27;
	ld.global.u32 	%r28, [%rd24+20];
	st.global.u16 	[%rd25+12], %r28;
	ld.global.u32 	%r29, [%rd24+24];
	st.global.u16 	[%rd25+14], %r29;
	ld.global.u32 	%r30, [%rd24+28];
	st.global.u16 	[%rd25+16], %r30;
	ld.global.u32 	%r31, [%rd24+32];
	st.global.u16 	[%rd25+18], %r31;
	ld.global.u32 	%r32, [%rd24+36];
	st.global.u16 	[%rd25+20], %r32;
	ld.global.u32 	%r33, [%rd24+40];
	st.global.u16 	[%rd25+22], %r33;
	ld.global.u32 	%r34, [%rd24+44];
	st.global.u16 	[%rd25+24], %r34;
	ld.global.u32 	%r35, [%rd24+48];
	st.global.u16 	[%rd25+26], %r35;
	ld.global.u32 	%r36, [%rd24+52];
	st.global.u16 	[%rd25+28], %r36;
	ld.global.u32 	%r37, [%rd24+56];
	st.global.u16 	[%rd25+30], %r37;
	add.s64 	%rd28, %rd28, 32;
	add.s64 	%rd27, %rd27, -16;
	add.s64 	%rd26, %rd26, -16;
	add.s32 	%r38, %r38, 16;
	setp.ne.s32	%p1, %r38, 0;
	@%p1 bra 	BB0_1;

	ret;
}

	// .globl	_Z12memoryKernelPPjPtiyiS_
.visible .entry _Z12memoryKernelPPjPtiyiS_(
	.param .u64 _Z12memoryKernelPPjPtiyiS__param_0,
	.param .u64 _Z12memoryKernelPPjPtiyiS__param_1,
	.param .u32 _Z12memoryKernelPPjPtiyiS__param_2,
	.param .u64 _Z12memoryKernelPPjPtiyiS__param_3,
	.param .u32 _Z12memoryKernelPPjPtiyiS__param_4,
	.param .u64 _Z12memoryKernelPPjPtiyiS__param_5
)
{
	.local .align 8 .b8 	__local_depot1[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<22>;
	.reg .b32 	%r<160>;
	.reg .b64 	%rd<68>;


	mov.u64 	%SPL, __local_depot1;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd11, [_Z12memoryKernelPPjPtiyiS__param_0];
	ld.param.u32 	%r57, [_Z12memoryKernelPPjPtiyiS__param_2];
	ld.param.u32 	%r58, [_Z12memoryKernelPPjPtiyiS__param_4];
	ld.param.u64 	%rd12, [_Z12memoryKernelPPjPtiyiS__param_5];
	shr.s32 	%r60, %r57, 31;
	shr.u32 	%r61, %r60, 22;
	add.s32 	%r62, %r57, %r61;
	shr.s32 	%r1, %r62, 10;
	// inline asm
	mov.u64 	%rd13, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd14, %clock64;
	// inline asm
	cvt.s64.s32	%rd15, %r57;
	shr.u64 	%rd1, %rd15, 2;
	cvt.u32.u64	%r63, %rd1;
	mov.u32 	%r137, 0;
	setp.lt.s32	%p1, %r63, 1;
	@%p1 bra 	BB1_12;

	bfe.u32 	%r70, %r57, 2, 2;
	mov.u32 	%r137, 0;
	setp.eq.s32	%p2, %r70, 0;
	@%p2 bra 	BB1_2;

	setp.eq.s32	%p3, %r70, 1;
	@%p3 bra 	BB1_4;
	bra.uni 	BB1_5;

BB1_4:
	mov.u32 	%r132, %r137;
	bra.uni 	BB1_8;

BB1_2:
	mov.u32 	%r134, %r137;
	bra.uni 	BB1_9;

BB1_5:
	setp.eq.s32	%p4, %r70, 2;
	mov.u32 	%r130, %r137;
	@%p4 bra 	BB1_7;

	cvta.to.global.u64 	%rd16, %rd12;
	ld.global.u32 	%r137, [%rd16];
	mov.u32 	%r130, 1;

BB1_7:
	cvta.to.global.u64 	%rd17, %rd12;
	mul.wide.u32 	%rd18, %r130, 4;
	add.s64 	%rd19, %rd17, %rd18;
	ld.global.u32 	%r72, [%rd19];
	add.s32 	%r137, %r72, %r137;
	add.s32 	%r132, %r130, 1;

BB1_8:
	cvta.to.global.u64 	%rd20, %rd12;
	mul.wide.s32 	%rd21, %r132, 4;
	add.s64 	%rd22, %rd20, %rd21;
	ld.global.u32 	%r73, [%rd22];
	add.s32 	%r137, %r73, %r137;
	add.s32 	%r134, %r132, 1;

BB1_9:
	setp.lt.u32	%p5, %r63, 4;
	@%p5 bra 	BB1_12;

	cvta.to.global.u64 	%rd25, %rd12;
	mul.wide.s32 	%rd26, %r134, 4;
	add.s64 	%rd65, %rd25, %rd26;

BB1_11:
	ld.global.u32 	%r75, [%rd65];
	add.s32 	%r76, %r75, %r137;
	ld.global.u32 	%r77, [%rd65+4];
	add.s32 	%r78, %r77, %r76;
	ld.global.u32 	%r79, [%rd65+8];
	add.s32 	%r80, %r79, %r78;
	ld.global.u32 	%r81, [%rd65+12];
	add.s32 	%r137, %r81, %r80;
	add.s64 	%rd65, %rd65, 16;
	add.s32 	%r134, %r134, 4;
	setp.lt.s32	%p6, %r134, %r63;
	@%p6 bra 	BB1_11;

BB1_12:
	// inline asm
	mov.u64 	%rd27, %clock64;
	// inline asm
	bar.sync 	0;
	mov.u32 	%r82, %ctaid.y;
	mov.u32 	%r83, %nctaid.x;
	mov.u32 	%r84, %ctaid.x;
	mad.lo.s32 	%r85, %r83, %r82, %r84;
	shl.b32 	%r86, %r85, 2;
	mov.u32 	%r87, %tid.x;
	mov.u32 	%r88, %tid.y;
	mov.u32 	%r89, %ntid.x;
	mad.lo.s32 	%r90, %r89, %r88, %r87;
	shr.s32 	%r91, %r90, 31;
	shr.u32 	%r92, %r91, 27;
	add.s32 	%r93, %r90, %r92;
	shr.u32 	%r94, %r93, 5;
	add.s32 	%r95, %r94, %r86;
	mul.lo.s32 	%r96, %r1, %r95;
	shl.b32 	%r19, %r96, 5;
	mov.u32 	%r152, 1;
	max.s32 	%r20, %r1, %r152;
	cvta.to.global.u64 	%rd28, %rd11;
	ld.global.u64 	%rd5, [%rd28];
	bar.sync 	0;
	mov.u32 	%r148, 0;
	setp.lt.s32	%p7, %r57, 1024;
	mov.u32 	%r147, %r19;
	@%p7 bra 	BB1_23;

	and.b32  	%r103, %r20, 3;
	mov.u32 	%r139, 1;
	mov.u32 	%r148, 0;
	setp.eq.s32	%p8, %r103, 0;
	@%p8 bra 	BB1_14;

	setp.eq.s32	%p9, %r103, 1;
	mov.u32 	%r140, %r19;
	@%p9 bra 	BB1_19;

	setp.eq.s32	%p10, %r103, 2;
	mov.u32 	%r138, %r19;
	@%p10 bra 	BB1_18;

	mul.wide.s32 	%rd29, %r19, 4;
	add.s64 	%rd30, %rd5, %rd29;
	ld.u32 	%r138, [%rd30];
	mov.u32 	%r139, 2;

BB1_18:
	mul.wide.s32 	%rd31, %r138, 4;
	add.s64 	%rd32, %rd5, %rd31;
	ld.u32 	%r140, [%rd32];
	mov.u32 	%r148, %r139;

BB1_19:
	mul.wide.s32 	%rd33, %r140, 4;
	add.s64 	%rd34, %rd5, %rd33;
	ld.u32 	%r147, [%rd34];
	add.s32 	%r148, %r148, 1;
	mov.u32 	%r144, %r147;
	bra.uni 	BB1_20;

BB1_14:
	mov.u32 	%r147, %r19;
	mov.u32 	%r144, %r148;

BB1_20:
	setp.lt.u32	%p11, %r20, 4;
	@%p11 bra 	BB1_21;
	bra.uni 	BB1_22;

BB1_21:
	mov.u32 	%r147, %r144;
	bra.uni 	BB1_23;

BB1_22:
	mul.wide.s32 	%rd35, %r147, 4;
	add.s64 	%rd36, %rd5, %rd35;
	ld.u32 	%r105, [%rd36];
	mul.wide.s32 	%rd37, %r105, 4;
	add.s64 	%rd38, %rd5, %rd37;
	ld.u32 	%r106, [%rd38];
	mul.wide.s32 	%rd39, %r106, 4;
	add.s64 	%rd40, %rd5, %rd39;
	ld.u32 	%r107, [%rd40];
	mul.wide.s32 	%rd41, %r107, 4;
	add.s64 	%rd42, %rd5, %rd41;
	ld.u32 	%r147, [%rd42];
	add.s32 	%r148, %r148, 4;
	setp.lt.s32	%p12, %r148, %r1;
	@%p12 bra 	BB1_22;

BB1_23:
	bar.sync 	0;
	mul.lo.s32 	%r108, %r148, %r58;
	mad.lo.s32 	%r158, %r108, %r147, %r19;
	bar.sync 	0;
	or.b32  	%r39, %r85, %r90;
	setp.ne.s32	%p13, %r39, 0;
	@%p13 bra 	BB1_25;

	// inline asm
	mov.u64 	%rd66, %clock64;
	// inline asm

BB1_25:
	mov.u32 	%r159, 0;
	@%p7 bra 	BB1_37;

	and.b32  	%r122, %r20, 3;
	mov.u32 	%r159, 0;
	setp.eq.s32	%p15, %r122, 0;
	@%p15 bra 	BB1_27;

	setp.eq.s32	%p16, %r122, 1;
	@%p16 bra 	BB1_29;
	bra.uni 	BB1_30;

BB1_29:
	mov.u32 	%r152, %r159;
	bra.uni 	BB1_33;

BB1_27:
	mov.u32 	%r155, %r159;
	bra.uni 	BB1_34;

BB1_30:
	setp.eq.s32	%p17, %r122, 2;
	@%p17 bra 	BB1_32;

	mul.wide.s32 	%rd45, %r158, 4;
	add.s64 	%rd46, %rd5, %rd45;
	ld.u32 	%r158, [%rd46];
	mov.u32 	%r152, 2;

BB1_32:
	mul.wide.s32 	%rd47, %r158, 4;
	add.s64 	%rd48, %rd5, %rd47;
	ld.u32 	%r158, [%rd48];

BB1_33:
	mul.wide.s32 	%rd49, %r158, 4;
	add.s64 	%rd50, %rd5, %rd49;
	ld.u32 	%r158, [%rd50];
	add.s32 	%r159, %r152, 1;
	mov.u32 	%r155, %r158;

BB1_34:
	setp.lt.u32	%p18, %r20, 4;
	@%p18 bra 	BB1_35;
	bra.uni 	BB1_36;

BB1_35:
	mov.u32 	%r158, %r155;
	bra.uni 	BB1_37;

BB1_36:
	mul.wide.s32 	%rd51, %r158, 4;
	add.s64 	%rd52, %rd5, %rd51;
	ld.u32 	%r124, [%rd52];
	mul.wide.s32 	%rd53, %r124, 4;
	add.s64 	%rd54, %rd5, %rd53;
	ld.u32 	%r125, [%rd54];
	mul.wide.s32 	%rd55, %r125, 4;
	add.s64 	%rd56, %rd5, %rd55;
	ld.u32 	%r126, [%rd56];
	mul.wide.s32 	%rd57, %r126, 4;
	add.s64 	%rd58, %rd5, %rd57;
	ld.u32 	%r158, [%rd58];
	add.s32 	%r159, %r159, 4;
	setp.lt.s32	%p19, %r159, %r1;
	@%p19 bra 	BB1_36;

BB1_37:
	bar.sync 	0;
	@%p13 bra 	BB1_39;

	// inline asm
	mov.u64 	%rd67, %clock64;
	// inline asm

BB1_39:
	bar.sync 	0;
	bar.sync 	0;
	st.u32 	[%rd5], %r159;
	add.s32 	%r127, %r158, %r137;
	st.u32 	[%rd5+4], %r127;
	st.u32 	[%rd5+8], %r137;
	sub.s64 	%rd10, %rd67, %rd66;
	st.u32 	[%rd5+12], %rd10;
	@%p13 bra 	BB1_41;

	add.u64 	%rd61, %SP, 0;
	add.u64 	%rd62, %SPL, 0;
	st.local.u64 	[%rd62], %rd10;
	mov.u64 	%rd63, $str;
	cvta.global.u64 	%rd64, %rd63;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd64;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd61;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r128, [retval0+0];
	
	//{
	}// Callseq End 0

BB1_41:
	ret;
}


